import streamlit as st
import pandas as pd
import yfinance as yf
import requests
import os
import re
from datetime import datetime, timedelta

# --- 1. é é¢é…ç½®èˆ‡ç™½çš®æ›¸åƒæ•¸ ---
st.set_page_config(page_title="è™•ç½®é æ¸¬ç³»çµ± V7", layout="wide", page_icon="âš–ï¸")

# ä¾æ“šç™½çš®æ›¸é‡åŒ–æ¨™æº–å®šç¾© [cite: 23, 25, 26]
QUANT_RULES = {
    "VOLATILITY_6D": 0.32,      # 6æ—¥ç´¯ç©æ¼²è·Œå¹… > 32% 
    "SPREAD_BENCHMARK": 0.20,   # èˆ‡å¤§ç›¤ä¹–é›¢ > 20% 
    "VOLUME_X": 5.0,            # 6æ—¥å‡é‡è¼ƒ60æ—¥å‡é‡æ”¾å¤§ 5 å€ 
    "TURNOVER_SINGLE": 0.10,    # å–®æ—¥é€±è½‰ç‡ > 10% 
    "PE_LIMIT": 60,             # æœ¬ç›Šæ¯” > 60 [cite: 26]
    "PB_LIMIT": 6,              # æ·¨å€¼æ¯” > 6 [cite: 26]
}

DB_FILE = "history_db.csv"
JAIL_FILE = "jail_list.csv"

# --- 2. è‡ªå‹•çˆ¬èŸ²æ¨¡çµ„ (æŠ“å–åœ‹ç¥¨è­‰åˆ¸å¯¦æ™‚è³‡è¨Š) ---
def fetch_official_data():
    """å¾åœ‹ç¥¨è­‰åˆ¸æŠ“å–ä»Šæ—¥æœ€æ–°çš„æ³¨æ„èˆ‡è™•ç½®åå–® [cite: 6, 18]"""
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    # çˆ¬å–è™•ç½®è‚¡ç¶²å€ 
    url_dis = "https://www.ibfs.com.tw/stock3/measuringstock.aspx?xy=6&xt=1"
    # çˆ¬å–æ³¨æ„è‚¡ç¶²å€ [cite: 1]
    url_att = "https://www.ibfs.com.tw/stock3/default13-1.aspx?xy=8&xt=1"
    
    try:
        res_dis = requests.get(url_dis, headers=headers, verify=False, timeout=5)
        res_att = requests.get(url_att, headers=headers, verify=False, timeout=5)
        
        # æŠ“å–è¡¨æ ¼
        dis_list = pd.read_html(res_dis.text)[0]
        att_list = pd.read_html(res_att.text)[0]
        
        return dis_list, att_list
    except Exception as e:
        st.error(f"çˆ¬èŸ²é€£ç·šå¤±æ•—: {e}")
        return None, None

# --- 3. æ ¸å¿ƒé æ¸¬é‚è¼¯ (è¨ˆæ•¸å™¨èˆ‡é‡åŒ–åˆ†æ) ---
def update_history_db(att_df):
    """å°‡ä»Šæ—¥æ³¨æ„è‚¡å­˜å…¥è³‡æ–™åº«ï¼Œç”¨æ–¼è¨ˆç®— 10æ—¥6æ¬¡ ç­‰é‚è¼¯ """
    if att_df is None or att_df.empty: return
    
    today = datetime.now().strftime("%Y-%m-%d")
    # å‡è¨­ att_df çš„ä»£è™Ÿåœ¨ 'ä»£è™Ÿ' æˆ– 'è­‰åˆ¸åç¨±' æ¬„ä½
    new_records = []
    for _, row in att_df.iterrows():
        code = str(row.get('ä»£è™Ÿ', row.get('è­‰åˆ¸åç¨±', ''))).split('(')[-1].replace(')', '')
        new_records.append({"æ—¥æœŸ": today, "ä»£è™Ÿ": code, "ç‹€æ…‹": "æ³¨æ„"})
    
    if os.path.exists(DB_FILE):
        old_db = pd.read_csv(DB_FILE)
        combined = pd.concat([old_db, pd.DataFrame(new_records)]).drop_duplicates(subset=['æ—¥æœŸ', 'ä»£è™Ÿ'])
        combined.to_csv(DB_FILE, index=False)
    else:
        pd.DataFrame(new_records).to_csv(DB_FILE, index=False)

def analyze_risk_counter(stock_code):
    """è¨ˆç®— 10 æ—¥å…§æ³¨æ„æ¬¡æ•¸ """
    if not os.path.exists(DB_FILE): return 0
    db = pd.read_csv(DB_FILE)
    db['æ—¥æœŸ'] = pd.to_datetime(db['æ—¥æœŸ'])
    
    # å–æœ€è¿‘ 10 å€‹ç‡Ÿæ¥­æ—¥ 
    ten_days_ago = datetime.now() - timedelta(days=15)
    stock_history = db[(db['ä»£è™Ÿ'].astype(str) == str(stock_code)) & (db['æ—¥æœŸ'] >= ten_days_ago)]
    return len(stock_history)

# --- 4. ä»‹é¢è¨­è¨ˆ ---
st.title("ğŸ”¥ å°è‚¡è™•ç½®è‚¡é æ¸¬å¼•æ“ V7")
st.markdown(f"**ç•¶å‰æ—¥æœŸï¼š** {datetime.now().strftime('%Y-%m-%d')} | **ç›£è¦–æº–å‰‡ï¼š** ä¾æ“šè­‰äº¤æ‰€è™•ç½®ä½œæ¥­è¦é» ")

# å´é‚Šæ¬„æ§åˆ¶
if st.sidebar.button("ğŸ”„ ç«‹å³åŒæ­¥æœ€æ–°çˆ¬èŸ²è³‡æ–™"):
    dis, att = fetch_official_data()
    if att is not None:
        update_history_db(att)
        st.sidebar.success("è³‡æ–™åº«å·²æ›´æ–°ï¼")

# é é¢åˆ†é 
tab1, tab2, tab3 = st.tabs(["ğŸ¯ è™•ç½®é¢¨éšªé æ¸¬", "ğŸ”’ ç›®å‰è¢«é—œç¦é–‰", "ğŸ“‰ æ­·å²çµ±è¨ˆ"])

with tab1:
    st.subheader("åˆ†æç›®æ¨™è‚¡ç¥¨æ˜¯å¦å³å°‡ã€Œè¢«é—œã€")
    target_code = st.text_input("è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿ (ä¾‹å¦‚: 4931)", "4931")
    
    if st.button("é–‹å§‹é‡åŒ–è¨ºæ–·"):
        # 1. æŠ“å–è‚¡åƒ¹èˆ‡é‡èƒ½ 
        ticker = yf.Ticker(f"{target_code}.TW")
        hist = ticker.history(period="65d")
        
        if not hist.empty:
            # æ¼²å¹…è¨ˆç®—
            ret_6d = (hist.iloc[-1]['Close'] - hist.iloc[-6]['Close']) / hist.iloc[-6]['Close']
            # é‡èƒ½æ”¾å¤§ 
            vol_6 = hist.iloc[-6:]['Volume'].mean()
            vol_60 = hist.iloc[-60:]['Volume'].mean()
            vol_ratio = vol_6 / vol_60
            
            # è¨ˆæ•¸å™¨ 
            att_count = analyze_risk_counter(target_code)
            
            # é¡¯ç¤ºæŒ‡æ¨™
            c1, c2, c3 = st.columns(3)
            c1.metric("6æ—¥ç´¯ç©æ¼²å¹…", f"{ret_6d*100:.1f}%", delta="é–€æª» 32%")
            c2.metric("é‡èƒ½æ”¾å¤§å€æ•¸", f"{vol_ratio:.1f}x", delta="é–€æª» 5x")
            c3.metric("10æ—¥å…§æ³¨æ„æ¬¡æ•¸", f"{att_count} æ¬¡", delta="é–€æª» 6æ¬¡")
            
            # é æ¸¬çµè«–
            if att_count >= 5:
                st.error(f"ğŸš¨ é«˜åº¦é è­¦ï¼š{target_code} å·²ç´¯ç© {att_count} æ¬¡æ³¨æ„ï¼Œå† 1 æ¬¡å³é€²å…¥è™•ç½®ï¼ ")
            elif ret_6d > 0.30:
                st.warning(f"âš ï¸ æ¼²å¹…é è­¦ï¼šæ¼²å¹…å·²æ¥è¿‘ 32% é–€æª»ï¼Œéš¨æ™‚å¯èƒ½åˆ—å…¥æ³¨æ„è‚¡ç¥¨ã€‚ ")
            else:
                st.success("âœ… ç›®å‰å„é …æŒ‡æ¨™å°šåœ¨å®‰å…¨ç¯„åœå…§ã€‚")
        else:
            st.warning("æŸ¥ç„¡è‚¡ç¥¨è³‡æ–™ï¼Œè«‹æª¢æŸ¥ä»£è™Ÿæˆ–å¸‚å ´ï¼ˆ.TW / .TWOï¼‰")

with tab2:
    st.subheader("å‡ºé—œå€’æ•¸æ¸…å–®")
    dis, att = fetch_official_data()
    if dis is not None:
        st.dataframe(dis, use_container_width=True)
        st.caption("è³‡æ–™ä¾†æºï¼šåœ‹ç¥¨è­‰åˆ¸å®˜æ–¹è™•ç½®å…¬å‘Š ")
    else:
        st.info("è«‹é»æ“Šå·¦å´ã€ŒåŒæ­¥ã€æŒ‰éˆ•ç²å–è³‡æ–™ã€‚")

with tab3:
    st.subheader("æ­·å²æ³¨æ„ç´€éŒ„ (ç”¨æ–¼è¨ˆæ•¸å™¨)")
    if os.path.exists(DB_FILE):
        st.table(pd.read_csv(DB_FILE).tail(10))
    else:
        st.write("å°šç„¡æ­·å²è³‡æ–™ã€‚")
